name: ğŸ“Š Deploy Observability Stack (MICRO - Free Tier Optimized)

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment'
        required: true
        type: choice
        options:
          - stg
          - prd
      action:
        description: 'Action'
        required: true
        type: choice
        options:
          - install
          - uninstall
          - upgrade

env:
  AWS_REGION: us-east-1

jobs:
  deploy-observability-micro:
    name: ğŸ“ˆ ${{ github.event.inputs.action }} Observability Stack (MICRO)
    runs-on: ubuntu-latest
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ğŸ”§ Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: â˜¸ï¸ Configure kubectl
        run: |
          aws eks update-kubeconfig \
            --name tx01-eks-${{ github.event.inputs.environment }} \
            --region ${{ env.AWS_REGION }}
          
          echo "âœ… Kubectl configured"
          kubectl cluster-info
      
      - name: ğŸ” Pre-flight Check & Capacity Validation
        run: |
          echo "ğŸ” Checking cluster capacity..."
          echo ""
          
          NODE_COUNT=$(kubectl get nodes --no-headers 2>/dev/null | grep -c "Ready" || echo 0)
          READY_NODES=$(kubectl get nodes --no-headers 2>/dev/null | grep -c " Ready " || echo 0)
          TOTAL_PODS=$(kubectl get pods -A --no-headers --field-selector=status.phase!=Succeeded,status.phase!=Failed 2>/dev/null | wc -l)
          POD_CAPACITY=$((READY_NODES * 4))
          FREE_SLOTS=$((POD_CAPACITY - TOTAL_PODS))
          
          echo "ğŸ“Š Cluster Status:"
          echo "   Nodes Ready: $READY_NODES/$NODE_COUNT"
          echo "   Total pods (Running+Pending): $TOTAL_PODS"
          echo "   Pod capacity: $POD_CAPACITY"
          echo "   Free slots: $FREE_SLOTS"
          echo ""
          
          # Clean up any orphaned LoadBalancer services first
          echo "ğŸ§¹ Cleaning up LoadBalancer services..."
          kubectl delete svc -n monitoring kube-prometheus-stack-grafana --ignore-not-found=true 2>/dev/null || true
          echo "âœ… Cleanup complete"
          echo ""
          
          # Capacity check - need at least 3 free slots for minimal stack
          # (Prometheus=1, Grafana=1, KSM=1, Operator=1 = 4 pods total)
          if [ $FREE_SLOTS -lt 3 ]; then
            echo "âŒ INSUFFICIENT CAPACITY"
            echo ""
            echo "Current state:"
            echo "  - Free slots: $FREE_SLOTS"
            echo "  - Required: 3 (for 4-pod observability stack)"
            echo ""
            echo "ğŸ”§ Options to fix:"
            echo "  1. Scale down other workloads"
            echo "  2. Increase node count: gh workflow run scale-eks-nodes.yml -f action=scale-up -f node_count=8"
            echo "  3. Remove orphan nodes: Check for EC2 instances not joined to cluster"
            echo ""
            kubectl get nodes
            echo ""
            kubectl get pods -A -o wide | head -20
            exit 1
          fi
          
          echo "âœ… Sufficient capacity available ($FREE_SLOTS free slots)"
          echo ""
          echo "ğŸ¯ Ready to install observability stack"
          echo "   Will deploy: Prometheus (1), Grafana (1), KSM (1), Operator (1) = 4 pods"
          echo ""
      
      - name: ğŸ¯ Setup Helm
        uses: azure/setup-helm@v4
        with:
          version: 'v3.13.0'
      
      - name: ğŸ“¦ Add Helm Repositories
        run: |
          echo "ğŸ“¦ Adding Helm repositories..."
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo update
          echo "âœ… Repositories added and updated"
      
      - name: ğŸ“ Create Monitoring Namespace
        if: github.event.inputs.action == 'install'
        run: |
          echo "ğŸ“ Creating monitoring namespace..."
          kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
          echo "âœ… Namespace ready"
      
      - name: ğŸ” Validate Grafana Password Secret
        if: github.event.inputs.action == 'install' || github.event.inputs.action == 'upgrade'
        run: |
          echo "ğŸ” Validating GRAFANA_PASSWORD secret..."
          
          if [ -z "${{ secrets.GRAFANA_PASSWORD }}" ]; then
            echo "âŒ ERROR: GRAFANA_PASSWORD secret is not configured!"
            echo ""
            echo "ğŸ“ To configure it:"
            echo "   1. Go to: https://github.com/${{ github.repository }}/settings/secrets/actions"
            echo "   2. Click 'New repository secret'"
            echo "   3. Name: GRAFANA_PASSWORD"
            echo "   4. Value: <your-strong-password>"
            echo ""
            echo "âš ï¸  Use a strong password for production environments!"
            exit 1
          fi
          
          PASSWORD_LENGTH=$(echo -n "${{ secrets.GRAFANA_PASSWORD }}" | wc -c)
          if [ $PASSWORD_LENGTH -lt 8 ]; then
            echo "âš ï¸  WARNING: Password is too short (less than 8 characters)"
            echo "ğŸ“ Consider using a stronger password for production"
          fi
          
          echo "âœ… GRAFANA_PASSWORD secret is configured (length: $PASSWORD_LENGTH chars)"
          echo "ğŸ”’ Password will be securely applied to Grafana deployment"
      
      - name: ğŸ”Œ Ensure EBS CSI Driver is installed
        if: github.event.inputs.action == 'install'
        run: |
          echo "ğŸ” Checking EBS CSI Driver addon..."
          
          ADDON_STATUS=$(aws eks describe-addon \
            --cluster-name tx01-eks-${{ github.event.inputs.environment }} \
            --addon-name aws-ebs-csi-driver \
            --region ${{ env.AWS_REGION }} \
            --query 'addon.status' \
            --output text 2>/dev/null || echo "NOT_FOUND")
          
          if [ "$ADDON_STATUS" = "NOT_FOUND" ]; then
            echo "âš ï¸  EBS CSI Driver not found, installing..."
            
            # Check if IAM role exists
            ROLE_EXISTS=$(aws iam get-role \
              --role-name tx01-eks-ebs-csi-driver \
              --query 'Role.RoleName' \
              --output text 2>/dev/null || echo "NOT_FOUND")
            
            if [ "$ROLE_EXISTS" = "NOT_FOUND" ]; then
              echo "Creating IAM role for EBS CSI Driver..."
              
              # Get OIDC provider
              OIDC_ID=$(aws eks describe-cluster \
                --name tx01-eks-${{ github.event.inputs.environment }} \
                --region ${{ env.AWS_REGION }} \
                --query 'cluster.identity.oidc.issuer' \
                --output text | cut -d '/' -f 5)
              
              ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
              
              # Create trust policy
              cat > trust-policy.json <<EOF
          {
            "Version": "2012-10-17",
            "Statement": [{
              "Effect": "Allow",
              "Principal": {
                "Federated": "arn:aws:iam::${ACCOUNT_ID}:oidc-provider/oidc.eks.us-east-1.amazonaws.com/id/${OIDC_ID}"
              },
              "Action": "sts:AssumeRoleWithWebIdentity",
              "Condition": {
                "StringEquals": {
                  "oidc.eks.us-east-1.amazonaws.com/id/${OIDC_ID}:aud": "sts.amazonaws.com",
                  "oidc.eks.us-east-1.amazonaws.com/id/${OIDC_ID}:sub": "system:serviceaccount:kube-system:ebs-csi-controller-sa"
                }
              }
            }]
          }
          EOF
              
              # Create role
              aws iam create-role \
                --role-name tx01-eks-ebs-csi-driver \
                --assume-role-policy-document file://trust-policy.json
              
              # Attach policy
              aws iam attach-role-policy \
                --role-name tx01-eks-ebs-csi-driver \
                --policy-arn arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy
              
              echo "âœ… IAM role created"
            else
              echo "âœ… IAM role already exists"
            fi
            
            # Install addon
            aws eks create-addon \
              --cluster-name tx01-eks-${{ github.event.inputs.environment }} \
              --addon-name aws-ebs-csi-driver \
              --service-account-role-arn arn:aws:iam::${ACCOUNT_ID}:role/tx01-eks-ebs-csi-driver \
              --region ${{ env.AWS_REGION }}
            
            echo "â³ Waiting for addon to be ACTIVE..."
            aws eks wait addon-active \
              --cluster-name tx01-eks-${{ github.event.inputs.environment }} \
              --addon-name aws-ebs-csi-driver \
              --region ${{ env.AWS_REGION }}
            
            echo "âœ… EBS CSI Driver installed"
          elif [ "$ADDON_STATUS" = "ACTIVE" ]; then
            echo "âœ… EBS CSI Driver already active"
          else
            echo "âš ï¸  EBS CSI Driver status: $ADDON_STATUS"
            echo "Waiting for it to become ACTIVE..."
            aws eks wait addon-active \
              --cluster-name tx01-eks-${{ github.event.inputs.environment }} \
              --addon-name aws-ebs-csi-driver \
              --region ${{ env.AWS_REGION }}
            echo "âœ… EBS CSI Driver is now active"
          fi
      
      - name: ğŸ“Š Install Prometheus + Grafana (MICRO Stack)
        if: github.event.inputs.action == 'install'
        run: |
          echo "ğŸ“Š Installing kube-prometheus-stack (PLAN 3 - Ultra MICRO)..."
          echo ""
          echo "ğŸ¯ PLAN 3 Stack Components (4 pods total):"
          echo "   âœ… Prometheus Server (1 pod, 1Gi storage, 128Mi RAM)"
          echo "   âœ… Grafana (1 pod, no persistence, 64Mi RAM)"
          echo "   âœ… Kube State Metrics (1 pod, 32Mi RAM)"
          echo "   âœ… Prometheus Operator (1 pod, 64Mi RAM)"
          echo "   âŒ AlertManager (disabled)"
          echo "   âŒ Node Exporter (disabled)"
          echo "   âŒ Admission Webhooks (disabled)"
          echo ""
          echo "ğŸ“Š Total Resources: ~288Mi RAM, ~105m CPU"
          echo "ğŸ¯ Target: 7 nodes t3.micro = 28 pods capacity"
          echo ""
          echo "ğŸ’¡ For logs, use AWS CloudWatch (Free Tier: 5GB/month)"
          echo ""
          
          # Increase kubectl timeout
          export KUBECTL_TIMEOUT=120s
          
          # Verify cluster connectivity with retry
          echo "ğŸ” Verifying cluster connectivity..."
          for i in {1..3}; do
            if kubectl cluster-info --request-timeout=30s; then
              echo "âœ… Cluster is reachable"
              break
            else
              echo "âš ï¸  Attempt $i/3 failed, retrying in 10s..."
              sleep 10
            fi
          done
          
          helm upgrade --install kube-prometheus-stack \
            prometheus-community/kube-prometheus-stack \
            --namespace monitoring \
            --create-namespace \
            --values k8s/prometheus-micro-values.yaml \
            --set grafana.adminPassword=${{ secrets.GRAFANA_PASSWORD }} \
            --set prometheus-node-exporter.enabled=false \
            --set nodeExporter.enabled=false \
            --timeout=20m \
            --wait
          
          echo ""
          echo "âœ… Prometheus + Grafana (PLAN 3 - Ultra MICRO) installed"
      
      - name: ğŸ”„ Upgrade Stack
        if: github.event.inputs.action == 'upgrade'
        run: |
          echo "ğŸ”„ Upgrading observability stack (MICRO)..."
          echo ""
          echo "ğŸ§¹ Cleaning LoadBalancer service first..."
          kubectl delete svc -n monitoring kube-prometheus-stack-grafana --ignore-not-found=true
          echo ""
          
          helm upgrade kube-prometheus-stack \
            prometheus-community/kube-prometheus-stack \
            --namespace monitoring \
            --values k8s/prometheus-micro-values.yaml \
            --set grafana.adminPassword=${{ secrets.GRAFANA_PASSWORD }} \
            --set prometheus-node-exporter.enabled=false \
            --set nodeExporter.enabled=false \
            --wait --timeout=15m
          
          echo ""
          echo "âœ… Stack upgraded with ClusterIP service"
          echo "ğŸ’¡ Access Grafana: kubectl port-forward -n monitoring svc/kube-prometheus-stack-grafana 3000:80"
      
      - name: ğŸ—‘ï¸ Uninstall Stack
        if: github.event.inputs.action == 'uninstall'
        run: |
          echo "ğŸ—‘ï¸ Uninstalling observability stack (MICRO)..."
          
          helm uninstall kube-prometheus-stack -n monitoring || echo "Already uninstalled"
          
          echo "âš ï¸  Namespace 'monitoring' preserved (contains PVCs)"
          echo "To fully remove: kubectl delete namespace monitoring --grace-period=0 --force"
          
          echo "âœ… Stack uninstalled"
      
      - name: â³ Wait for Pods
        if: github.event.inputs.action == 'install' || github.event.inputs.action == 'upgrade'
        run: |
          echo "â³ Waiting for pods to be ready..."
          
          kubectl wait --for=condition=ready pod \
            -l app.kubernetes.io/name=prometheus \
            -n monitoring \
            --timeout=300s || echo "Prometheus pods not ready yet (may still be starting)"
          
          kubectl wait --for=condition=ready pod \
            -l app.kubernetes.io/name=grafana \
            -n monitoring \
            --timeout=300s || echo "Grafana pods not ready yet (may still be starting)"
          
          kubectl wait --for=condition=ready pod \
            -l app.kubernetes.io/name=kube-state-metrics \
            -n monitoring \
            --timeout=300s || echo "Kube State Metrics not ready yet (may still be starting)"
          
          echo "âœ… Pods are ready"
      
      - name: ğŸ“Š Get Grafana URL
        if: github.event.inputs.action == 'install' || github.event.inputs.action == 'upgrade'
        id: grafana-url
        run: |
          echo "ğŸ“Š Getting Grafana URL..."
          
          # Wait for LoadBalancer to be ready
          sleep 30
          
          GRAFANA_URL=$(kubectl get svc -n monitoring kube-prometheus-stack-grafana \
            -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "pending")
          
          if [ "$GRAFANA_URL" = "pending" ] || [ -z "$GRAFANA_URL" ]; then
            echo "â³ LoadBalancer is still provisioning..."
            echo "   Run this command later to get the URL:"
            echo "   kubectl get svc -n monitoring kube-prometheus-stack-grafana"
          else
            echo "grafana_url=$GRAFANA_URL" >> $GITHUB_OUTPUT
            echo "âœ… Grafana URL: http://$GRAFANA_URL"
          fi
      
      - name: ğŸ“Š Show Final Status
        if: github.event.inputs.action == 'install' || github.event.inputs.action == 'upgrade'
        run: |
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š OBSERVABILITY STACK (PLAN 3 - Ultra MICRO) - COMPLETE"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo ""
          
          echo "ğŸ“¦ Installed Components:"
          kubectl get pods -n monitoring -o wide
          echo ""
          
          echo "ğŸ’¾ Storage:"
          kubectl get pvc -n monitoring
          echo ""
          
          echo "ğŸŒ Services:"
          kubectl get svc -n monitoring
          echo ""
          
          GRAFANA_URL=$(kubectl get svc -n monitoring kube-prometheus-stack-grafana \
            -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "pending")
          
          TOTAL_PODS=$(kubectl get pods -A --no-headers | wc -l)
          NODE_COUNT=$(kubectl get nodes --no-headers | wc -l)
          POD_CAPACITY=$((NODE_COUNT * 4))
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š CLUSTER STATUS"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo ""
          echo "   Nodes: $NODE_COUNT"
          echo "   Pods: $TOTAL_PODS / $POD_CAPACITY"
          echo "   Free slots: $((POD_CAPACITY - TOTAL_PODS))"
          echo ""
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ¯ ACCESS GRAFANA"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo ""
          
          if [ "$GRAFANA_URL" != "pending" ] && [ -n "$GRAFANA_URL" ]; then
            echo "   ğŸŒ URL: http://$GRAFANA_URL"
            echo "   ğŸ‘¤ User: admin"
            echo "   ğŸ”’ Password: (from GRAFANA_PASSWORD secret)"
            echo ""
            echo "   â³ Wait 2-3 minutes for DNS propagation"
          else
            echo "   â³ LoadBalancer still provisioning..."
            echo "   Get URL with: kubectl get svc -n monitoring kube-prometheus-stack-grafana"
          fi
          echo ""
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ’¡ PLAN 3 - ULTRA MICRO STACK"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo ""
          echo "   âœ… Optimized for 7x t3.micro nodes (Free Tier)"
          echo "   âœ… Total: 4 pods, ~288Mi RAM, ~105m CPU"
          echo "   âœ… Prometheus: 2d retention, 1GB storage"
          echo "   âœ… Grafana: Ephemeral storage (no persistence)"
          echo "   âŒ AlertManager disabled (use CloudWatch Alarms)"
          echo "   âŒ Node Exporter disabled (saves resources)"
          echo "   âŒ Loki disabled (use CloudWatch Logs - 5GB/month free)"
          echo ""
          echo "   ğŸ“ˆ For full stack: Use deploy-observability.yml (requires t3.small+)"
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
