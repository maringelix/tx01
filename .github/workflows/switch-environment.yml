name: ğŸ”„ Switch Environment (Simplified)

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment'
        required: true
        type: choice
        options:
          - stg
          - prd
        default: 'stg'
      mode:
        description: 'Compute mode'
        required: true
        type: choice
        options:
          - ec2
          - eks
        default: 'ec2'

env:
  AWS_REGION: us-east-1
  KUBECTL_VERSION: 1.32.0

jobs:
  switch:
    name: Switch to ${{ inputs.mode }} mode
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Get EC2 instances
      id: ec2-info
      run: |
        INSTANCE_IDS=$(aws ec2 describe-instances \
          --region ${{ env.AWS_REGION }} \
          --filters "Name=tag:Name,Values=tx01-ec2-*-${{ inputs.environment }}" "Name=instance-state-name,Values=running,stopped" \
          --query 'Reservations[].Instances[].InstanceId' \
          --output text)
        echo "instance_ids=$INSTANCE_IDS" >> $GITHUB_OUTPUT
        echo "Found EC2 instances: $INSTANCE_IDS"

    - name: Install kubectl (for EKS operations)
      if: inputs.mode == 'eks'
      run: |
        curl -LO "https://dl.k8s.io/release/v${{ env.KUBECTL_VERSION }}/bin/linux/amd64/kubectl"
        chmod +x kubectl
        sudo mv kubectl /usr/local/bin/

    - name: Switch to EC2 mode
      if: inputs.mode == 'ec2'
      run: |
        echo "ğŸ”„ Switching to EC2 mode..."
        echo ""
        
        # Check if EKS cluster exists
        CLUSTER_NAME=$(aws eks list-clusters --region ${{ env.AWS_REGION }} --query "clusters[?contains(@, 'tx01-eks-${{ inputs.environment }}')]" --output text || echo "")
        
        if [ -n "$CLUSTER_NAME" ]; then
          echo "ğŸ“‰ Scaling down EKS deployment..."
          aws eks update-kubeconfig --name $CLUSTER_NAME --region ${{ env.AWS_REGION }}
          
          CURRENT_REPLICAS=$(kubectl get deployment tx01-app -o jsonpath='{.spec.replicas}' 2>/dev/null || echo "0")
          echo "   Current replicas: $CURRENT_REPLICAS"
          
          if [ "$CURRENT_REPLICAS" != "0" ]; then
            kubectl scale deployment tx01-app --replicas=0
            echo "   Waiting for pods to terminate..."
            kubectl wait --for=delete pod -l app=tx01 --timeout=60s 2>/dev/null || true
          fi
          
          echo "âœ… EKS deployment scaled to 0 (no app pods running)"
          echo "   Note: System pods (ALB Controller, CoreDNS, etc) remain active"
          echo ""
        fi
        
        # Start EC2 instances
        if [ -n "${{ steps.ec2-info.outputs.instance_ids }}" ]; then
          echo "â–¶ï¸  Starting EC2 instances..."
          aws ec2 start-instances \
            --instance-ids ${{ steps.ec2-info.outputs.instance_ids }} \
            --region ${{ env.AWS_REGION }}
          
          echo "â³ Waiting for instances to be running..."
          aws ec2 wait instance-running \
            --instance-ids ${{ steps.ec2-info.outputs.instance_ids }} \
            --region ${{ env.AWS_REGION }}
          
          echo "âœ… EC2 instances are now running"
          echo ""
          
          # Get ALB DNS
          ALB_DNS=$(aws elbv2 describe-load-balancers \
            --region ${{ env.AWS_REGION }} \
            --query "LoadBalancers[?contains(LoadBalancerName, 'tx01-alb-${{ inputs.environment }}')].DNSName" \
            --output text)
          
          echo "ğŸ¯ Your application is now running on EC2!"
          echo "   Access via: http://$ALB_DNS"
        else
          echo "âš ï¸  No EC2 instances found"
          exit 1
        fi

    - name: Switch to EKS mode
      if: inputs.mode == 'eks'
      run: |
        echo "ğŸ”„ Switching to EKS mode..."
        echo ""
        
        # Get EKS cluster
        CLUSTER_NAME=$(aws eks list-clusters --region ${{ env.AWS_REGION }} --query "clusters[?contains(@, 'tx01-eks-${{ inputs.environment }}')]" --output text)
        
        if [ -z "$CLUSTER_NAME" ]; then
          echo "âŒ EKS cluster not found. Please provision it first using EKS Deploy workflow."
          exit 1
        fi
        
        # Update kubeconfig
        aws eks update-kubeconfig --name $CLUSTER_NAME --region ${{ env.AWS_REGION }}
        
        # Check current deployment status
        echo "ğŸ“Š Current deployment status:"
        kubectl get deployment tx01-app -o wide || echo "Deployment not found"
        echo ""
        
        # Check if HPA exists and get target replicas
        HPA_EXISTS=$(kubectl get hpa tx01-hpa --ignore-not-found -o name)
        
        if [ -n "$HPA_EXISTS" ]; then
          echo "âš ï¸  HPA detected - it will manage replicas automatically"
          TARGET_REPLICAS=$(kubectl get hpa tx01-hpa -o jsonpath='{.spec.minReplicas}')
          echo "   HPA minReplicas: $TARGET_REPLICAS"
        else
          echo "â„¹ï¸  No HPA found - using manual scaling (t3.micro mode)"
          TARGET_REPLICAS=1
        fi
        
        # Scale up deployment
        echo "ğŸ“ˆ Scaling up EKS deployment to $TARGET_REPLICAS replica(s)..."
        kubectl scale deployment tx01-app --replicas=$TARGET_REPLICAS
        
        echo "â³ Waiting for pods to be ready (timeout: 5 minutes)..."
        kubectl wait --for=condition=ready pod -l app=tx01 --timeout=300s || echo "âš ï¸ Timeout waiting for pods (may still be starting)"
        
        echo "âœ… Pods are ready"
        echo ""
        
        # Show pods status
        echo "ğŸ“‹ Pods status:"
        kubectl get pods -l app=tx01 -o wide
        echo ""
        
        # Check pod capacity (especially for t3.micro)
        echo "ğŸ“Š Cluster pod capacity:"
        TOTAL_PODS=$(kubectl get pods -A --no-headers | wc -l)
        NODE_COUNT=$(kubectl get nodes --no-headers | wc -l)
        echo "   Total pods running: $TOTAL_PODS"
        echo "   Total nodes: $NODE_COUNT"
        echo ""
        
        # Warning for high pod density
        if [ $TOTAL_PODS -ge 14 ]; then
          echo "âš ï¸  WARNING: High pod density detected ($TOTAL_PODS pods)"
          echo "   t3.micro supports max 4 pods/node (16 total for 4 nodes)"
          echo "   Consider scaling nodes or upgrading to t3.small if adding more workloads"
          echo ""
        fi
        
        # Check Ingress status
        echo "ğŸ“‹ Ingress status:"
        kubectl get ingress tx01-ingress -o wide
        echo ""
        
        # Get Ingress-managed ALB
        INGRESS_ALB=$(kubectl get ingress tx01-ingress -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
        
        if [ -n "$INGRESS_ALB" ]; then
          echo "âœ… ALB managed by Ingress Controller is ready"
          echo "   DNS: $INGRESS_ALB"
          echo ""
          echo "â³ Note: It may take 2-3 minutes for DNS to propagate and health checks to pass."
        else
          echo "âš ï¸  Ingress ALB not ready yet. This may take 2-3 minutes."
          echo "   Run: kubectl get ingress tx01-ingress -o wide"
          echo ""
        fi
        
        # Stop EC2 instances to save costs
        if [ -n "${{ steps.ec2-info.outputs.instance_ids }}" ]; then
          echo "ğŸ›‘ Stopping EC2 instances to save costs..."
          aws ec2 stop-instances \
            --instance-ids ${{ steps.ec2-info.outputs.instance_ids }} \
            --region ${{ env.AWS_REGION }}
          
          echo "âœ… EC2 instances stopped"
          echo ""
        fi
        
        echo "âœ… Switched to EKS mode"
        echo ""
        echo "ğŸ¯ Your application is now running on EKS!"
        if [ -n "$INGRESS_ALB" ]; then
          echo "   Access via: http://$INGRESS_ALB"
        else
          echo "   Get the URL with: kubectl get ingress tx01-ingress"
        fi

    - name: Verify status
      run: |
        echo ""
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "ğŸ“Š FINAL STATUS"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        echo "Environment: ${{ inputs.environment }}"
        echo "Mode: ${{ inputs.mode }}"
        echo ""
        
        case "${{ inputs.mode }}" in
          ec2)
            echo "âœ… EC2 instances: Active"
            echo "ğŸ’¤ EKS cluster: Scaled to 0 (pods not running)"
            echo "ğŸ’° Estimated cost: ~\$50/month (EC2 only)"
            echo ""
            echo "Note: EC2 instances serve traffic via existing ALB"
            ;;
          eks)
            # Get actual pod count
            CLUSTER_NAME=$(aws eks list-clusters --region ${{ env.AWS_REGION }} --query "clusters[?contains(@, 'tx01-eks-${{ inputs.environment }}')]" --output text)
            aws eks update-kubeconfig --name $CLUSTER_NAME --region ${{ env.AWS_REGION }} 2>/dev/null
            APP_PODS=$(kubectl get pods -l app=tx01 --no-headers 2>/dev/null | wc -l || echo "1")
            
            echo "ğŸ’¤ EC2 instances: Stopped"
            echo "âœ… EKS cluster: Active ($APP_PODS app pod(s) running)"
            echo "ğŸ’° Estimated cost: ~\$73/month (EKS \$73 + 4x t3.micro Free Tier)"
            echo ""
            echo "Configuration:"
            echo "   - Instance type: t3.micro (1GB RAM, 2 vCPU)"
            echo "   - Nodes: 4 (max 4 pods/node = 16 total capacity)"
            echo "   - HPA: $(kubectl get hpa tx01-hpa --ignore-not-found -o name 2>/dev/null | grep -q hpa && echo 'Enabled' || echo 'Disabled (t3.micro mode)')"
            echo "   - Metrics Server: $(kubectl get deployment metrics-server -n kube-system --ignore-not-found -o name 2>/dev/null | grep -q metrics && echo 'Enabled' || echo 'Disabled (t3.micro mode)')"
            echo ""
            echo "Note: EKS pods serve traffic via ALB Ingress Controller"
            echo "      The Ingress Controller automatically manages routing"
            ;;
        esac
        echo ""
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
